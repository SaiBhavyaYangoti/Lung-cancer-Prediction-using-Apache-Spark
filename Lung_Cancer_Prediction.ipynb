{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4177274-11e6-48bd-b2bf-490c51a185f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lung_Cancer\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "os.environ[\"SPARK_HOME\"] = \"/home/iiitdmk-sic40/spark-3.5.5\"  # Update if different\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"  # Update if needed\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"jupyter\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"] = \"notebook\"\n",
    "\n",
    "import findspark  \n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://172.16.72.48:7077\") \\\n",
    "    .appName(\"Lung_Cancer_prediction\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Lung_Cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a4633a5-7269-4ff3-a7af-697352d2aeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-------+--------------+-------+-------------+---------------+--------+--------+--------+-----------------+--------+-------------------+---------------------+----------+-----------+\n",
      "|GENDER|AGE|SMOKING|YELLOW_FINGERS|ANXIETY|PEER_PRESSURE|CHRONIC DISEASE|FATIGUE |ALLERGY |WHEEZING|ALCOHOL CONSUMING|COUGHING|SHORTNESS OF BREATH|SWALLOWING DIFFICULTY|CHEST PAIN|LUNG_CANCER|\n",
      "+------+---+-------+--------------+-------+-------------+---------------+--------+--------+--------+-----------------+--------+-------------------+---------------------+----------+-----------+\n",
      "|     M| 69|      1|             2|      2|            1|              1|       2|       1|       2|                2|       2|                  2|                    2|         2|        YES|\n",
      "|     M| 74|      2|             1|      1|            1|              2|       2|       2|       1|                1|       1|                  2|                    2|         2|        YES|\n",
      "|     F| 59|      1|             1|      1|            2|              1|       2|       1|       2|                1|       2|                  2|                    1|         2|         NO|\n",
      "|     M| 63|      2|             2|      2|            1|              1|       1|       1|       1|                2|       1|                  1|                    2|         2|         NO|\n",
      "|     F| 63|      1|             2|      1|            1|              1|       1|       1|       2|                1|       2|                  2|                    1|         1|         NO|\n",
      "+------+---+-------+--------------+-------+-------------+---------------+--------+--------+--------+-----------------+--------+-------------------+---------------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"hdfs://localhost:9000/user/iiitdmk-sic40/survey_lung_cancer.csv\", header=True, inferSchema=True)\n",
    "df.show(5)  # Display the first 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c71278ed-9086-42af-a84a-418096f5c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|LUNG_CANCER|count|\n",
      "+-----------+-----+\n",
      "|        YES|  270|\n",
      "|         NO|   39|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"LUNG_CANCER\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b4f5127-ce48-4580-92f5-40592fb6cb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-------+--------------+-------+-------------+---------------+--------+--------+--------+-----------------+--------+-------------------+---------------------+----------+-----------+--------------+-----+--------------------+\n",
      "|GENDER|AGE|SMOKING|YELLOW_FINGERS|ANXIETY|PEER_PRESSURE|CHRONIC DISEASE|FATIGUE |ALLERGY |WHEEZING|ALCOHOL CONSUMING|COUGHING|SHORTNESS OF BREATH|SWALLOWING DIFFICULTY|CHEST PAIN|LUNG_CANCER|GENDER_INDEXED|label|            features|\n",
      "+------+---+-------+--------------+-------+-------------+---------------+--------+--------+--------+-----------------+--------+-------------------+---------------------+----------+-----------+--------------+-----+--------------------+\n",
      "|     M| 69|      1|             2|      2|            1|              1|       2|       1|       2|                2|       2|                  2|                    2|         2|        YES|           0.0|  0.0|[69.0,1.0,2.0,2.0...|\n",
      "|     M| 74|      2|             1|      1|            1|              2|       2|       2|       1|                1|       1|                  2|                    2|         2|        YES|           0.0|  0.0|[74.0,2.0,1.0,1.0...|\n",
      "|     F| 59|      1|             1|      1|            2|              1|       2|       1|       2|                1|       2|                  2|                    1|         2|         NO|           1.0|  1.0|[59.0,1.0,1.0,1.0...|\n",
      "|     M| 63|      2|             2|      2|            1|              1|       1|       1|       1|                2|       1|                  1|                    2|         2|         NO|           0.0|  1.0|[63.0,2.0,2.0,2.0...|\n",
      "|     F| 63|      1|             2|      1|            1|              1|       1|       1|       2|                1|       2|                  2|                    1|         1|         NO|           1.0|  1.0|[63.0,1.0,2.0,1.0...|\n",
      "+------+---+-------+--------------+-------+-------------+---------------+--------+--------+--------+-----------------+--------+-------------------+---------------------+----------+-----------+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Convert categorical columns\n",
    "indexer = StringIndexer(inputCol=\"GENDER\", outputCol=\"GENDER_INDEXED\", handleInvalid=\"keep\")\n",
    "label_indexer = StringIndexer(inputCol=\"LUNG_CANCER\", outputCol=\"label\", handleInvalid=\"keep\")\n",
    "\n",
    "# Assemble feature columns\n",
    "feature_columns = [c for c in df.columns if c not in [\"GENDER\", \"LUNG_CANCER\"]]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline = Pipeline(stages=[indexer, label_indexer, assembler])\n",
    "df_prepared = pipeline.fit(df).transform(df)\n",
    "df_prepared.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bf2a202-35f6-4e5f-959c-ca9c7db251c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert to Pandas\n",
    "pdf = df_prepared.select(\"features\", \"label\").toPandas()\n",
    "X = np.array(pdf['features'].tolist())\n",
    "y = pdf['label'].values\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Convert back to Spark DataFrame\n",
    "resampled_pdf = pd.DataFrame(X_res, columns=[f\"feature_{i}\" for i in range(X_res.shape[1])])\n",
    "resampled_pdf['label'] = y_res\n",
    "resampled_df = spark.createDataFrame(resampled_pdf)\n",
    "\n",
    "# Assemble Features Again\n",
    "feature_columns = [f\"feature_{i}\" for i in range(X_res.shape[1])]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "resampled_df = assembler.transform(resampled_df).select(\"features\", \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8874538-4aac-405c-842e-758ddc930b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "resampled_df = scaler.fit(resampled_df).transform(resampled_df).select(\"scaled_features\", \"label\")\n",
    "resampled_df = resampled_df.withColumnRenamed(\"scaled_features\", \"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e518b7a4-0f2d-463d-85be-11800f9be645",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = resampled_df.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbc0d311-d2b0-401b-a85b-27099c2c1e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "predictions = lr_model.transform(test_data)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51f2837e-bd3e-44d5-b485-9af91183bba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.96      0.94        50\n",
      "         1.0       0.96      0.92      0.94        50\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "predictions_pd = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Extract true labels and predicted labels as NumPy arrays\n",
    "y_true = predictions_pd[\"label\"].to_numpy()\n",
    "y_pred = predictions_pd[\"prediction\"].to_numpy()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, digits=2)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcb20bea-8aa1-4ae5-bff7-7c9cb518e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "predictions = dt_model.transform(test_data)\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Decision Tree Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4399354b-9c4b-4d6b-b2c3-eb783fdba351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.96      0.94        50\n",
      "         1.0       0.96      0.92      0.94        50\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "predictions_pd = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Extract true labels and predicted labels as NumPy arrays\n",
    "y_true = predictions_pd[\"label\"].to_numpy()\n",
    "y_pred = predictions_pd[\"prediction\"].to_numpy()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, digits=2)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d90f55c-9dcb-40f7-bbad-ce6c72db271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=10)\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "predictions = rf_model.transform(test_data)\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88433926-77e4-44f7-a478-9a7d35e1b8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96        50\n",
      "         1.0       0.98      0.94      0.96        50\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.96      0.96      0.96       100\n",
      "weighted avg       0.96      0.96      0.96       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "predictions_pd = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Extract true labels and predicted labels as NumPy arrays\n",
    "y_true = predictions_pd[\"label\"].to_numpy()\n",
    "y_pred = predictions_pd[\"prediction\"].to_numpy()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, digits=2)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c2bceb2-b2a1-443b-88a1-13642ce238b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT Accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "gbt_model = gbt.fit(train_data)\n",
    "\n",
    "predictions = gbt_model.transform(test_data)\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"GBT Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4bb3ce68-cf3e-428b-9f49-2ecd0f093511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.96      0.95        50\n",
      "         1.0       0.96      0.94      0.95        50\n",
      "\n",
      "    accuracy                           0.95       100\n",
      "   macro avg       0.95      0.95      0.95       100\n",
      "weighted avg       0.95      0.95      0.95       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "predictions_pd = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Extract true labels and predicted labels as NumPy arrays\n",
    "y_true = predictions_pd[\"label\"].to_numpy()\n",
    "y_pred = predictions_pd[\"prediction\"].to_numpy()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, digits=2)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfa428ff-8273-48ae-992a-b7b5e70d9ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|label|       norm_features|\n",
      "+--------------------+-----+--------------------+\n",
      "|[-5.0785065131700...|  1.0|[-0.8238146907153...|\n",
      "|[-2.2219277715584...|  0.0|[-0.5047557142075...|\n",
      "|[-1.3525342415027...|  0.0|[-0.3286034687401...|\n",
      "|[-1.2283351657804...|  0.0|[-0.3201667131354...|\n",
      "|[-1.1041360900582...|  0.0|[-0.2598713691607...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Drop \"norm_features\" if it already exists\n",
    "if \"norm_features\" in train_data.columns:\n",
    "    train_data = train_data.drop(\"norm_features\")\n",
    "if \"norm_features\" in test_data.columns:\n",
    "    test_data = test_data.drop(\"norm_features\")\n",
    "\n",
    "# Normalize features\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"norm_features\", p=2.0)\n",
    "train_data = normalizer.transform(train_data)\n",
    "test_data = normalizer.transform(test_data)\n",
    "\n",
    "train_data.show(5)  # Check transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bf703bd-fb20-49ef-a628-497aeedf7c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 925:=====================================>                 (11 + 5) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import FloatType\n",
    "import numpy as np\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Convert Spark DataFrame to Pandas for broadcasting\n",
    "train_pdf = train_data.select(\"norm_features\", \"label\").toPandas()\n",
    "\n",
    "# Broadcast training data\n",
    "train_broadcast = spark.sparkContext.broadcast(train_pdf)\n",
    "\n",
    "# Define UDF for Euclidean distance calculation\n",
    "def knn_predict(test_row, k=5):\n",
    "    test_features = np.array(test_row)\n",
    "    train_features = np.array(train_broadcast.value[\"norm_features\"].tolist())\n",
    "    train_labels = np.array(train_broadcast.value[\"label\"].tolist())\n",
    "\n",
    "    # Compute Euclidean distance\n",
    "    distances = np.linalg.norm(train_features - test_features, axis=1)\n",
    "\n",
    "    # Get indices of k nearest neighbors\n",
    "    k_indices = distances.argsort()[:k]\n",
    "\n",
    "    # Get majority label\n",
    "    knn_labels = train_labels[k_indices]\n",
    "    return float(np.bincount(knn_labels.astype(int)).argmax())\n",
    "\n",
    "# Register UDF\n",
    "from pyspark.sql.types import DoubleType\n",
    "knn_udf = udf(lambda features: float(knn_predict(features, k=5)), DoubleType())\n",
    "\n",
    "# Apply KNN prediction\n",
    "test_data = test_data.withColumn(\"prediction\", knn_udf(col(\"norm_features\")))\n",
    "\n",
    "# Evaluate KNN Model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(test_data)\n",
    "print(f\"KNN Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f932d7bc-4e66-4b75-9ad8-7438608ec042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.96      0.95        50\n",
      "         1.0       0.96      0.94      0.95        50\n",
      "\n",
      "    accuracy                           0.95       100\n",
      "   macro avg       0.95      0.95      0.95       100\n",
      "weighted avg       0.95      0.95      0.95       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "predictions_pd = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Extract true labels and predicted labels as NumPy arrays\n",
    "y_true = predictions_pd[\"label\"].to_numpy()\n",
    "y_pred = predictions_pd[\"prediction\"].to_numpy()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, digits=2)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16d0df69-c633-4ab1-b2eb-054a902ac40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/29 12:33:03 WARN Instrumentation: [3f3cb810] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Classification Accuracy: 0.9300\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Drop existing prediction column if it exists\n",
    "if \"prediction\" in test_data.columns:\n",
    "    test_data = test_data.drop(\"prediction\")\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Train the model\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Predict on test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Apply thresholding (Assume 0.5 as threshold)\n",
    "threshold = 0.5\n",
    "predictions = predictions.withColumn(\"prediction\", when(col(\"prediction\") >= threshold, 1.0).otherwise(0.0))\n",
    "\n",
    "# Ensure prediction is of DoubleType for evaluation\n",
    "predictions = predictions.withColumn(\"prediction\", col(\"prediction\").cast(DoubleType()))\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Linear Regression Classification Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45e3bf2b-ed20-4912-965c-378f228fb1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.92      0.93        50\n",
      "         1.0       0.92      0.94      0.93        50\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "predictions_pd = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Extract true labels and predicted labels as NumPy arrays\n",
    "y_true = predictions_pd[\"label\"].to_numpy()\n",
    "y_pred = predictions_pd[\"prediction\"].to_numpy()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, digits=2)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77d65244-f75d-4dac-81c6-9544a0978291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Accuracy: 0.9300\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Convert Spark DataFrame to Pandas\n",
    "train_pdf = train_data.select(\"features\", \"label\").toPandas()\n",
    "test_pdf = test_data.select(\"features\", \"label\").toPandas()\n",
    "\n",
    "# Extract feature vectors\n",
    "X_train = np.array(train_pdf[\"features\"].tolist())\n",
    "y_train = train_pdf[\"label\"].values\n",
    "X_test = np.array(test_pdf[\"features\"].tolist())\n",
    "y_test = test_pdf[\"label\"].values\n",
    "\n",
    "# Apply LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "predictions_pdf = pd.DataFrame({\"label\": y_test, \"prediction\": y_pred})\n",
    "predictions_df = spark.createDataFrame(predictions_pdf)\n",
    "\n",
    "# Evaluate Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_df)\n",
    "print(f\"LDA Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4781a329-7ba5-4dac-b6c5-c78882eac159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.92      0.93        50\n",
      "         1.0       0.92      0.94      0.93        50\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "predictions_pd = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Extract true labels and predicted labels as NumPy arrays\n",
    "y_true = predictions_pd[\"label\"].to_numpy()\n",
    "y_pred = predictions_pd[\"prediction\"].to_numpy()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, digits=2)\n",
    "\n",
    "# Print the report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0602393-895e-40a9-95fb-27676379e3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Define the MLP structure\n",
    "layers = [len(feature_columns), 10, 5, 2]  # Input, two hidden layers, output (binary classification)\n",
    "\n",
    "# Initialize MLP model\n",
    "mlp = MultilayerPerceptronClassifier(layers=layers, featuresCol=\"features\", labelCol=\"label\", blockSize=128, seed=42)\n",
    "\n",
    "# Train MLP\n",
    "mlp_model = mlp.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = mlp_model.transform(test_data)\n",
    "\n",
    "# Evaluate MLP Model\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"MLP Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "edfe5ae8-38ef-46a5-8675-208e99d0847b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99        50\n",
      "         1.0       0.98      1.00      0.99        50\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.99      0.99      0.99       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "predictions_pd = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Extract true labels and predicted labels as NumPy arrays\n",
    "y_true = predictions_pd[\"label\"].to_numpy()\n",
    "y_pred = predictions_pd[\"prediction\"].to_numpy()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, digits=2)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ede6d3a-28e2-4886-9da6-5d31330a14ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iiitdmk-sic40/.local/lib/python3.8/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Convert Spark DataFrame to Pandas\n",
    "train_pdf = train_data.select(\"features\", \"label\").toPandas()\n",
    "test_pdf = test_data.select(\"features\", \"label\").toPandas()\n",
    "\n",
    "# Extract feature vectors\n",
    "X_train = np.array(train_pdf[\"features\"].tolist())\n",
    "y_train = train_pdf[\"label\"].values\n",
    "X_test = np.array(test_pdf[\"features\"].tolist())\n",
    "y_test = test_pdf[\"label\"].values\n",
    "\n",
    "# Train AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(max_depth=2)\n",
    "ada = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "predictions_pdf = pd.DataFrame({\"label\": y_test, \"prediction\": y_pred})\n",
    "predictions_df = spark.createDataFrame(predictions_pdf)\n",
    "\n",
    "# Evaluate Accuracy\n",
    "accuracy = evaluator.evaluate(predictions_df)\n",
    "print(f\"AdaBoost Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad00462b-e57b-4cca-8e12-738fbb73b410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99        50\n",
      "         1.0       0.98      1.00      0.99        50\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.99      0.99      0.99       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "predictions_pd = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Extract true labels and predicted labels as NumPy arrays\n",
    "y_true = predictions_pd[\"label\"].to_numpy()\n",
    "y_pred = predictions_pd[\"prediction\"].to_numpy()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, digits=2)\n",
    "\n",
    "# Print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9e80e3f-e36d-4c7e-80b3-02508eebe169",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.write().overwrite().save(\"hdfs://localhost:9000/user/iiitdmk-sic40/mlp_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0b6d90f-0826-480c-b7c2-8f5b60971967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassificationModel\n",
    "\n",
    "# Load the trained MLP model\n",
    "loaded_model = MultilayerPerceptronClassificationModel.load(\"hdfs://localhost:9000/user/iiitdmk-sic40/mlp_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c85144cf-38d2-42dc-9fae-56f794d16c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+-------------------------------------------+\n",
      "|features                                                                                                                                                                                                                                                                               |prediction|probability                                |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+-------------------------------------------+\n",
      "|[-1.725131468669463,-1.128566881286277,1.0948311020643575,1.2427891063646062,1.290038741665748,1.219560625525346,0.8743623489040838,1.3797464451192876,1.2777686496557281,-0.8100453428151762,1.2118424029100245,0.8353824133330744,1.4789801890156642,-0.9530700101602935]            |0.0       |[1.0,2.7456082674490876E-42]               |\n",
      "|[-1.1041360900582469,1.029712662377487,1.0948311020643575,1.2427891063646062,1.290038741665748,1.219560625525346,-1.2964404019946687,1.3797464451192876,-0.8835884545220172,1.3175490090467752,-0.9487948849357377,-1.3964112155515658,1.4789801890156642,1.1672156187379479]          |0.0       |[1.0,5.1076803052915675E-33]               |\n",
      "|[-0.7315388628915173,1.029712662377487,1.0948311020643575,1.2427891063646062,-0.8687138616618232,-0.9195467286469297,-1.2964404019946687,-0.7683052148006201,-0.8835884545220172,-0.8100453428151762,-0.9487948849357377,0.8353824133330744,1.4789801890156642,-0.9530700101602935]    |1.0       |[3.410605438938367E-12,0.9999999999965894] |\n",
      "|[-0.2347425600025444,1.029712662377487,-1.0017143458873732,-0.8839721928046508,-0.8687138616618232,-0.9195467286469297,0.8743623489040838,-0.7683052148006201,-0.8835884545220172,-0.8100453428151762,-0.9487948849357377,0.8353824133330744,-0.7160118174044581,-0.9530700101602935]  |1.0       |[1.2354986957731215E-10,0.9999999998764502]|\n",
      "|[0.13785466716418524,-1.128566881286277,1.0948311020643575,-0.8839721928046508,-0.8687138616618232,-0.9195467286469297,-1.2964404019946687,-0.7683052148006201,1.2777686496557281,-0.8100453428151762,1.2118424029100245,0.8353824133330744,-0.7160118174044581,-0.9530700101602935]   |1.0       |[9.592025491569414E-13,0.9999999999990408] |\n",
      "|[0.7588500457754013,1.029712662377487,-1.0017143458873732,1.2427891063646062,-0.8687138616618232,-0.9195467286469297,0.8743623489040838,-0.7683052148006201,-0.8835884545220172,-0.8100453428151762,-0.9487948849357377,-1.3964112155515658,-0.7160118174044581,-0.9530700101602935]   |1.0       |[3.780923700174716E-12,0.999999999996219]  |\n",
      "|[1.255646348664374,1.029712662377487,1.0948311020643575,1.2427891063646062,1.290038741665748,1.219560625525346,-1.2964404019946687,1.3797464451192876,1.2777686496557281,1.3175490090467752,1.2118424029100245,-1.3964112155515658,1.4789801890156642,1.1672156187379479]              |0.0       |[1.0,5.952662144834512E-29]                |\n",
      "|[-1.8493305443917063,-1.128566881286277,1.0948311020643575,-0.8839721928046508,1.290038741665748,1.219560625525346,0.8743623489040838,-0.7683052148006201,1.2777686496557281,-0.8100453428151762,-0.9487948849357377,0.8353824133330744,1.4789801890156642,1.1672156187379479]         |0.0       |[1.0,4.039334922049037E-29]                |\n",
      "|[-0.7315388628915173,-1.128566881286277,-1.0017143458873732,-0.8839721928046508,-0.8687138616618232,1.219560625525346,-1.2964404019946687,-0.7683052148006201,1.2777686496557281,-0.8100453428151762,-0.9487948849357377,0.8353824133330744,1.4789801890156642,-0.9530700101602935]    |1.0       |[3.023543338457889E-7,0.9999996976456661]  |\n",
      "|[-0.7315388628915173,-1.128566881286277,-1.0017143458873732,-0.8839721928046508,1.290038741665748,1.219560625525346,0.8743623489040838,1.3797464451192876,1.2777686496557281,1.3175490090467752,-0.9487948849357377,-1.3964112155515658,-0.7160118174044581,1.1672156187379479]        |0.0       |[1.0,4.2669031426695895E-29]               |\n",
      "|[-0.2347425600025444,1.029712662377487,-1.0017143458873732,-0.8839721928046508,-0.8687138616618232,1.219560625525346,-1.2964404019946687,1.3797464451192876,1.2777686496557281,1.3175490090467752,1.2118424029100245,-1.3964112155515658,-0.7160118174044581,1.1672156187379479]       |0.0       |[1.0,3.3255029177672212E-18]               |\n",
      "|[0.13785466716418524,1.029712662377487,1.0948311020643575,1.2427891063646062,-0.8687138616618232,1.219560625525346,0.8743623489040838,1.3797464451192876,1.2777686496557281,-0.8100453428151762,-0.9487948849357377,0.8353824133330744,-0.7160118174044581,-0.9530700101602935]        |0.0       |[1.0,4.1175851876995156E-29]               |\n",
      "|[0.7588500457754013,-1.128566881286277,-1.0017143458873732,1.2427891063646062,-0.8687138616618232,1.219560625525346,-1.2964404019946687,1.3797464451192876,1.2777686496557281,1.3175490090467752,-0.9487948849357377,-1.3964112155515658,1.4789801890156642,-0.9530700101602935]       |0.0       |[1.0,1.5699297686295532E-28]               |\n",
      "|[1.8766417272755902,-1.128566881286277,1.0948311020643575,1.2427891063646062,1.290038741665748,1.219560625525346,0.8743623489040838,-0.7683052148006201,1.2777686496557281,1.3175490090467752,-0.9487948849357377,-1.3964112155515658,-0.7160118174044581,-0.9530700101602935]         |0.0       |[1.0,3.952931087083686E-29]                |\n",
      "|[-1.2283351657804902,1.029712662377487,-1.0017143458873732,-0.8839721928046508,-0.8687138616618232,1.219560625525346,0.8743623489040838,1.3797464451192876,1.2777686496557281,1.3175490090467752,-0.9487948849357377,-1.3964112155515658,1.4789801890156642,1.1672156187379479]        |0.0       |[1.0,3.967838871174125E-29]                |\n",
      "|[-0.48314071144703086,-1.128566881286277,-1.0017143458873732,-0.8839721928046508,-0.8687138616618232,-0.9195467286469297,0.8743623489040838,-0.7683052148006201,-0.8835884545220172,-0.8100453428151762,-0.9487948849357377,0.8353824133330744,-0.7160118174044581,-0.9530700101602935]|1.0       |[1.7450247967358677E-12,0.999999999998255] |\n",
      "|[-0.3589416357247876,-1.128566881286277,1.0948311020643575,1.2427891063646062,1.290038741665748,1.219560625525346,-1.2964404019946687,1.3797464451192876,1.2777686496557281,1.3175490090467752,1.2118424029100245,0.8353824133330744,1.4789801890156642,-0.9530700101602935]           |0.0       |[1.0,5.954338934270488E-29]                |\n",
      "|[-0.3589416357247876,1.029712662377487,-1.0017143458873732,-0.8839721928046508,1.290038741665748,-0.9195467286469297,-1.2964404019946687,-0.7683052148006201,-0.8835884545220172,1.3175490090467752,1.2118424029100245,0.8353824133330744,-0.7160118174044581,-0.9530700101602935]     |0.0       |[0.9999999549561986,4.504380132892888E-8]  |\n",
      "|[-0.2347425600025444,-1.128566881286277,1.0948311020643575,1.2427891063646062,-0.8687138616618232,-0.9195467286469297,-1.2964404019946687,-0.7683052148006201,1.2777686496557281,1.3175490090467752,1.2118424029100245,0.8353824133330744,1.4789801890156642,-0.9530700101602935]      |0.0       |[1.0,5.976920332552388E-29]                |\n",
      "|[1.131447272942131,-1.128566881286277,-1.0017143458873732,-0.8839721928046508,-0.8687138616618232,1.219560625525346,0.8743623489040838,1.3797464451192876,-0.8835884545220172,-0.8100453428151762,1.2118424029100245,0.8353824133330744,-0.7160118174044581,1.1672156187379479]        |0.0       |[1.0,4.660390122837412E-23]                |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+-------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already loaded the test dataset\n",
    "# Replace 'test_data' with your actual test DataFrame\n",
    "predictions = loaded_model.transform(test_data)\n",
    "\n",
    "# Show the predictions\n",
    "predictions.select(\"features\", \"prediction\", \"probability\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c1cefadb-7cb4-4af2-b22e-8117b2e25015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Input Layer Size: 14\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected Input Layer Size:\", loaded_model.getLayers()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "94c6489e-0761-460a-9410-cc3d118e8a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: No\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Example input: Replace these 14 values with actual values from your dataset\n",
    "single_input = [0.5, 1.2, 3.4, 2.1, 4.5, 5.6, 0.9, 3.3, 2.8, 1.5, 0.7, 6.1, 4.3, 2.2]  \n",
    "\n",
    "# Convert input to a Spark DataFrame\n",
    "single_df = spark.createDataFrame(\n",
    "    [Row(features=Vectors.dense(single_input))]\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "single_prediction = loaded_model.transform(single_df)\n",
    "\n",
    "# Extract prediction result\n",
    "predicted_value = single_prediction.select(\"prediction\").collect()[0][0]\n",
    "\n",
    "# Convert numeric prediction to Yes/No\n",
    "output_label = \"Yes\" if predicted_value == 1.0 else \"No\"\n",
    "print(\"Prediction:\", output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2399e242-2538-4f77-9b75-4550682ed0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46bfe49-4bc2-4893-bad2-69d7297abde5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
